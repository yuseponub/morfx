---
phase: 03-action-dsl-core
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/lib/tools/registry.ts
  - src/lib/tools/executor.ts
  - src/lib/audit/logger.ts
  - src/lib/audit/tool-logger.ts
autonomous: true

must_haves:
  truths:
    - "Tool inputs are validated before execution (invalid inputs rejected with clear error)"
    - "Tools can be tested without side effects (dry-run mode returns preview)"
    - "All tool executions are logged for audit (visible in tool_executions table)"
    - "Sensitive data is never logged (passwords, tokens, emails redacted)"
  artifacts:
    - path: "src/lib/tools/registry.ts"
      provides: "Tool registry singleton with validation"
      exports: ["toolRegistry", "ToolRegistry"]
    - path: "src/lib/tools/executor.ts"
      provides: "Tool execution engine with dry-run"
      exports: ["executeToolWithLogging"]
    - path: "src/lib/audit/logger.ts"
      provides: "Pino logger instance"
      exports: ["logger"]
    - path: "src/lib/audit/tool-logger.ts"
      provides: "Tool execution logging"
      exports: ["logToolExecution"]
  key_links:
    - from: "src/lib/tools/registry.ts"
      to: "ajv"
      via: "compiled validators"
      pattern: "this\\.ajv\\.compile"
    - from: "src/lib/audit/tool-logger.ts"
      to: "supabase"
      via: "insert to tool_executions"
      pattern: "from\\('tool_executions'\\)"
---

<objective>
Build the core Tool Registry and Executor with dry-run support and forensic logging.

Purpose: This is the heart of Action DSL. The registry validates inputs with JSON Schema, the executor handles dry-run vs real execution, and the logger creates forensic audit trails. Every future tool depends on this infrastructure.

Output: Working Tool Registry, Executor with dry-run, and Pino-based logging to Supabase.
</objective>

<execution_context>
@/home/jose147/.claude/get-shit-done/workflows/execute-plan.md
@/home/jose147/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/03-action-dsl-core/03-CONTEXT.md
@.planning/phases/03-action-dsl-core/03-RESEARCH.md
@.planning/phases/03-action-dsl-core/03-01-SUMMARY.md
@src/lib/tools/types.ts
@src/lib/supabase/server.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Pino Logger with Redaction</name>
  <files>src/lib/audit/logger.ts</files>
  <action>
Create the base Pino logger instance with security-focused redaction:

```typescript
// src/lib/audit/logger.ts
import pino from 'pino'

/**
 * Base Pino logger instance with sensitive data redaction
 *
 * Usage:
 * - logger.info({ event: 'tool_execution', tool: 'crm.contact.create' })
 * - logger.error({ event: 'tool_error', error: err.message })
 */
export const logger = pino({
  level: process.env.NODE_ENV === 'production' ? 'info' : 'debug',

  // Format level as string (easier to read in logs)
  formatters: {
    level: (label) => ({ level: label })
  },

  // Redact sensitive fields (CRITICAL for security)
  redact: {
    paths: [
      // Auth tokens
      '*.password',
      '*.token',
      '*.apiKey',
      '*.api_key',
      '*.accessToken',
      '*.refreshToken',
      // Personal data (GDPR compliance)
      '*.email',
      '*.phone',
      // Request headers
      '*.authorization',
      '*.cookie',
      // Nested paths
      'inputs.password',
      'inputs.token',
      'request_context.authorization'
    ],
    remove: true  // Remove entirely instead of replacing with [REDACTED]
  },

  // Add base context
  base: {
    app: 'morfx',
    env: process.env.NODE_ENV || 'development'
  },

  // Timestamp format (ISO 8601 for forensics)
  timestamp: pino.stdTimeFunctions.isoTime
})

/**
 * Create child logger for specific module
 */
export function createModuleLogger(module: string) {
  return logger.child({ module })
}
```

Key features:
- Redacts passwords, tokens, API keys automatically
- Removes sensitive personal data (email, phone) for GDPR
- ISO timestamps for forensic audit
- Child loggers for module-specific context
  </action>
  <verify>
```typescript
import { logger } from '@/lib/audit/logger'
logger.info({ test: 'works', password: 'secret' })
// Output should NOT contain "secret"
```
  </verify>
  <done>Pino logger exports correctly and redacts sensitive fields.</done>
</task>

<task type="auto">
  <name>Task 2: Create Tool Execution Logger</name>
  <files>src/lib/audit/tool-logger.ts</files>
  <action>
Create the tool-specific logging that persists to Supabase:

```typescript
// src/lib/audit/tool-logger.ts
import { logger, createModuleLogger } from './logger'
import { createClient } from '@/lib/supabase/server'
import type { ToolExecutionRecord } from '@/lib/tools/types'

const toolLogger = createModuleLogger('tools')

/**
 * Log a tool execution to both console (Pino) and database (Supabase)
 *
 * IMPORTANT: This function never throws. Logging failures are logged
 * but don't interrupt tool execution.
 */
export async function logToolExecution(
  execution: Omit<ToolExecutionRecord, 'id' | 'created_at'>
): Promise<string | null> {
  const executionId = crypto.randomUUID()
  const startTime = Date.now()

  // 1. Log to console (immediate, never fails)
  toolLogger.info({
    event: 'tool_execution',
    execution_id: executionId,
    tool_name: execution.tool_name,
    status: execution.status,
    duration_ms: execution.duration_ms,
    workspace_id: execution.workspace_id,
    source: execution.request_context.source
  })

  // 2. Persist to database (async, may fail)
  try {
    const supabase = await createClient()

    const { error } = await supabase
      .from('tool_executions')
      .insert({
        id: executionId,
        workspace_id: execution.workspace_id,
        tool_name: execution.tool_name,
        inputs: execution.inputs,
        outputs: execution.outputs,
        status: execution.status,
        error_message: execution.error_message,
        error_stack: execution.error_stack,
        started_at: execution.started_at,
        completed_at: execution.completed_at,
        duration_ms: execution.duration_ms,
        user_id: execution.user_id,
        session_id: execution.session_id,
        request_context: execution.request_context,
        snapshot_before: execution.snapshot_before,
        snapshot_after: execution.snapshot_after,
        batch_id: execution.batch_id,
        related_executions: execution.related_executions
      })

    if (error) {
      toolLogger.error({
        event: 'log_persist_error',
        execution_id: executionId,
        error: error.message
      })
      return null
    }

    toolLogger.debug({
      event: 'log_persisted',
      execution_id: executionId,
      persist_duration_ms: Date.now() - startTime
    })

    return executionId
  } catch (err) {
    // Never throw from logging
    toolLogger.error({
      event: 'log_persist_exception',
      execution_id: executionId,
      error: err instanceof Error ? err.message : 'Unknown error'
    })
    return null
  }
}

/**
 * Log an error that occurred outside normal tool execution
 */
export function logToolError(
  toolName: string,
  error: Error,
  context: Record<string, unknown> = {}
) {
  toolLogger.error({
    event: 'tool_error',
    tool_name: toolName,
    error: error.message,
    stack: error.stack,
    ...context
  })
}
```

Key design decisions:
- Never throws (logging must not interrupt business logic)
- Logs to console immediately (sync)
- Persists to DB asynchronously
- Uses service role for insert (bypasses RLS for audit integrity)
  </action>
  <verify>
```typescript
import { logToolExecution } from '@/lib/audit/tool-logger'
const id = await logToolExecution({
  workspace_id: 'test-ws',
  tool_name: 'test.tool',
  inputs: {},
  outputs: {},
  status: 'dry_run',
  started_at: new Date().toISOString(),
  completed_at: new Date().toISOString(),
  duration_ms: 100,
  request_context: { source: 'ui' }
})
console.log('Logged execution:', id)
```
  </verify>
  <done>Tool logger persists executions to Supabase and returns execution ID.</done>
</task>

<task type="auto">
  <name>Task 3: Build Tool Registry with Ajv Validation</name>
  <files>src/lib/tools/registry.ts</files>
  <action>
Create the Tool Registry singleton that manages tool registration and validation:

```typescript
// src/lib/tools/registry.ts
import Ajv from 'ajv'
import addFormats from 'ajv-formats'
import type {
  ToolSchema,
  RegisteredTool,
  ToolHandler,
  ToolMetadata
} from './types'
import { createModuleLogger } from '@/lib/audit/logger'

const logger = createModuleLogger('registry')

/**
 * Validation error thrown when tool inputs fail JSON Schema validation
 */
export class ValidationError extends Error {
  constructor(
    public readonly errors: Ajv['errors'],
    public readonly toolName: string
  ) {
    super(`Validation failed for tool ${toolName}: ${JSON.stringify(errors)}`)
    this.name = 'ValidationError'
  }
}

/**
 * Tool Registry - Singleton that manages tool registration, discovery, and validation
 *
 * Features:
 * - JSON Schema validation with Ajv (compiled validators for performance)
 * - Tool discovery via listTools()
 * - Permission checking against user roles
 * - MCP-compatible tool schemas
 */
class ToolRegistry {
  private ajv: Ajv
  private tools: Map<string, RegisteredTool & { _validate: ReturnType<Ajv['compile']> }>

  constructor() {
    this.ajv = new Ajv({
      strict: true,       // Enforce strict schema rules
      allErrors: true,    // Return all validation errors, not just first
      useDefaults: true,  // Apply default values from schema
      coerceTypes: false  // Don't coerce types (be strict)
    })
    addFormats(this.ajv)  // Add email, uri, date-time, etc.

    this.tools = new Map()

    logger.info({ event: 'registry_initialized' })
  }

  /**
   * Register a tool with its schema and handler
   *
   * @throws Error if tool name format is invalid
   * @throws Error if tool with same name already registered
   */
  register<TInput = unknown, TOutput = unknown>(
    schema: ToolSchema<TInput, TOutput>,
    handler: ToolHandler<TInput, TOutput>
  ): void {
    // Validate tool name format: module.entity.action
    const nameParts = schema.name.split('.')
    if (nameParts.length !== 3) {
      throw new Error(
        `Invalid tool name format: ${schema.name}. Expected: module.entity.action`
      )
    }

    // Check for duplicate
    if (this.tools.has(schema.name)) {
      throw new Error(`Tool already registered: ${schema.name}`)
    }

    // Compile validator for performance (10x faster than runtime compilation)
    const validate = this.ajv.compile(schema.inputSchema as object)

    // Store tool with compiled validator
    this.tools.set(schema.name, {
      ...schema,
      handler: handler as ToolHandler,
      _validate: validate
    })

    logger.info({
      event: 'tool_registered',
      tool_name: schema.name,
      module: schema.metadata.module,
      permissions: schema.metadata.permissions
    })
  }

  /**
   * Get a registered tool by name
   *
   * @throws Error if tool not found
   */
  getTool(name: string): RegisteredTool & { _validate: ReturnType<Ajv['compile']> } {
    const tool = this.tools.get(name)
    if (!tool) {
      throw new Error(`Unknown tool: ${name}`)
    }
    return tool
  }

  /**
   * Validate inputs against tool's JSON Schema
   *
   * @throws ValidationError if validation fails
   */
  validateInputs(toolName: string, inputs: unknown): void {
    const tool = this.getTool(toolName)

    if (!tool._validate(inputs)) {
      throw new ValidationError(tool._validate.errors, toolName)
    }
  }

  /**
   * Check if a tool exists
   */
  hasTool(name: string): boolean {
    return this.tools.has(name)
  }

  /**
   * List all registered tools (for discovery)
   */
  listTools(): ToolSchema[] {
    return Array.from(this.tools.values()).map(({ _validate, handler, ...schema }) => schema)
  }

  /**
   * List tools filtered by module
   */
  listToolsByModule(module: ToolMetadata['module']): ToolSchema[] {
    return this.listTools().filter((t) => t.metadata.module === module)
  }

  /**
   * List tools filtered by required permission
   */
  listToolsByPermission(permission: string): ToolSchema[] {
    return this.listTools().filter((t) =>
      t.metadata.permissions.includes(permission)
    )
  }

  /**
   * Get tool count (for debugging/metrics)
   */
  get size(): number {
    return this.tools.size
  }
}

// Export singleton instance
export const toolRegistry = new ToolRegistry()

// Export class for testing
export { ToolRegistry }
```

Key features:
- Compiled Ajv validators (10x faster than runtime)
- Tool name validation (module.entity.action format)
- Discovery methods (listTools, listToolsByModule, listToolsByPermission)
- ValidationError with detailed error information
  </action>
  <verify>
```typescript
import { toolRegistry, ValidationError } from '@/lib/tools/registry'

// Register a test tool
toolRegistry.register(
  {
    name: 'test.sample.create',
    description: 'Test tool',
    inputSchema: {
      type: 'object',
      properties: {
        name: { type: 'string' }
      },
      required: ['name'],
      additionalProperties: false
    },
    metadata: {
      module: 'system',
      entity: 'sample',
      action: 'create',
      reversible: false,
      requiresApproval: false,
      sideEffects: [],
      permissions: []
    }
  },
  async (input) => ({ success: true })
)

// List tools
console.log('Tools:', toolRegistry.listTools())
// Should show 1 tool

// Validate inputs
try {
  toolRegistry.validateInputs('test.sample.create', { name: 123 }) // Wrong type
} catch (e) {
  if (e instanceof ValidationError) {
    console.log('Validation errors:', e.errors)
  }
}
```
  </verify>
  <done>Tool Registry registers tools, validates inputs, and supports discovery.</done>
</task>

<task type="auto">
  <name>Task 4: Build Tool Executor with Dry-Run Support</name>
  <files>src/lib/tools/executor.ts</files>
  <action>
Create the Tool Executor that handles execution, dry-run, and logging:

```typescript
// src/lib/tools/executor.ts
import { toolRegistry, ValidationError } from './registry'
import { logToolExecution, logToolError } from '@/lib/audit/tool-logger'
import { hasPermission } from '@/lib/permissions'
import type {
  ExecutionContext,
  ExecutionOptions,
  ToolExecutionResult
} from './types'
import { createModuleLogger } from '@/lib/audit/logger'

const logger = createModuleLogger('executor')

/**
 * Permission error thrown when user lacks required permissions
 */
export class PermissionError extends Error {
  constructor(
    public readonly toolName: string,
    public readonly requiredPermissions: string[],
    public readonly userRole: string
  ) {
    super(
      `Permission denied for tool ${toolName}. Required: ${requiredPermissions.join(', ')}. Role: ${userRole}`
    )
    this.name = 'PermissionError'
  }
}

/**
 * Execute a tool with full logging and dry-run support
 *
 * Flow:
 * 1. Validate tool exists
 * 2. Validate inputs against JSON Schema
 * 3. Check permissions (if userRole provided)
 * 4. Execute handler (real or dry-run)
 * 5. Log execution to audit trail
 * 6. Return result
 *
 * @throws ValidationError if inputs fail schema validation
 * @throws PermissionError if user lacks required permissions
 * @throws Error if tool execution fails (only in real mode)
 */
export async function executeTool<TOutput = unknown>(
  toolName: string,
  inputs: unknown,
  options: ExecutionOptions,
  userRole?: string
): Promise<ToolExecutionResult<TOutput>> {
  const startedAt = new Date()
  const startTime = performance.now()

  try {
    // 1. Get tool and validate inputs
    const tool = toolRegistry.getTool(toolName)
    toolRegistry.validateInputs(toolName, inputs)

    // 2. Check permissions (if role provided and tool requires permissions)
    if (userRole && tool.metadata.permissions.length > 0) {
      const hasAllPermissions = tool.metadata.permissions.every((perm) =>
        hasPermission(userRole as any, perm as any)
      )

      if (!hasAllPermissions) {
        throw new PermissionError(
          toolName,
          tool.metadata.permissions,
          userRole
        )
      }
    }

    // 3. Execute handler
    const outputs = await tool.handler(
      inputs,
      options.context,
      options.dryRun ?? false
    )

    const completedAt = new Date()
    const durationMs = Math.round(performance.now() - startTime)

    // 4. Log execution
    const executionId = await logToolExecution({
      workspace_id: options.context.workspaceId,
      tool_name: toolName,
      inputs: inputs as Record<string, unknown>,
      outputs: outputs as Record<string, unknown>,
      status: options.dryRun ? 'dry_run' : 'success',
      started_at: startedAt.toISOString(),
      completed_at: completedAt.toISOString(),
      duration_ms: durationMs,
      user_id: options.context.userId ?? undefined,
      session_id: options.context.sessionId,
      request_context: options.context.requestContext
    })

    logger.debug({
      event: 'tool_executed',
      tool_name: toolName,
      execution_id: executionId,
      status: options.dryRun ? 'dry_run' : 'success',
      duration_ms: durationMs
    })

    return {
      id: executionId ?? crypto.randomUUID(),
      toolName,
      status: options.dryRun ? 'dry_run' : 'success',
      outputs: outputs as TOutput,
      durationMs
    }
  } catch (error) {
    const completedAt = new Date()
    const durationMs = Math.round(performance.now() - startTime)
    const errorMessage = error instanceof Error ? error.message : 'Unknown error'
    const errorStack = error instanceof Error ? error.stack : undefined

    // Log error execution
    const executionId = await logToolExecution({
      workspace_id: options.context.workspaceId,
      tool_name: toolName,
      inputs: inputs as Record<string, unknown>,
      outputs: {},
      status: 'error',
      error_message: errorMessage,
      error_stack: errorStack,
      started_at: startedAt.toISOString(),
      completed_at: completedAt.toISOString(),
      duration_ms: durationMs,
      user_id: options.context.userId ?? undefined,
      session_id: options.context.sessionId,
      request_context: options.context.requestContext
    })

    // Re-throw validation and permission errors (client should handle)
    if (error instanceof ValidationError || error instanceof PermissionError) {
      throw error
    }

    // Log unexpected errors
    logToolError(toolName, error instanceof Error ? error : new Error(errorMessage), {
      execution_id: executionId,
      workspace_id: options.context.workspaceId
    })

    return {
      id: executionId ?? crypto.randomUUID(),
      toolName,
      status: 'error',
      outputs: {} as TOutput,
      durationMs,
      error: {
        message: errorMessage,
        stack: errorStack
      }
    }
  }
}

/**
 * Execute a tool with automatic context from Server Action
 * Convenience wrapper for UI-triggered executions
 */
export async function executeToolFromUI<TOutput = unknown>(
  toolName: string,
  inputs: unknown,
  workspaceId: string,
  userId: string,
  userRole: string,
  dryRun = false
): Promise<ToolExecutionResult<TOutput>> {
  return executeTool<TOutput>(toolName, inputs, {
    dryRun,
    context: {
      workspaceId,
      userId,
      requestContext: {
        source: 'ui'
      }
    }
  }, userRole)
}

// Re-export errors for consumers
export { ValidationError } from './registry'
```

Key features:
- Dry-run mode (dryRun: true skips persistence)
- Permission checking against user role
- Full forensic logging on success and error
- Convenience wrapper for UI (executeToolFromUI)
- Clean error hierarchy (ValidationError, PermissionError)
  </action>
  <verify>
```typescript
import { executeTool, ValidationError } from '@/lib/tools/executor'
import { toolRegistry } from '@/lib/tools/registry'

// Register test tool
toolRegistry.register(
  {
    name: 'test.echo.run',
    description: 'Echo test',
    inputSchema: {
      type: 'object',
      properties: { message: { type: 'string' } },
      required: ['message'],
      additionalProperties: false
    },
    metadata: {
      module: 'system',
      entity: 'echo',
      action: 'run',
      reversible: false,
      requiresApproval: false,
      sideEffects: [],
      permissions: []
    }
  },
  async (input: { message: string }, ctx, dryRun) => {
    if (dryRun) return { echoed: `[DRY RUN] ${input.message}` }
    return { echoed: input.message }
  }
)

// Test dry-run
const dryResult = await executeTool('test.echo.run', { message: 'hello' }, {
  dryRun: true,
  context: {
    workspaceId: 'ws-123',
    userId: 'user-123',
    requestContext: { source: 'ui' }
  }
})
console.log('Dry run:', dryResult)
// status === 'dry_run', outputs.echoed === '[DRY RUN] hello'

// Test real execution
const realResult = await executeTool('test.echo.run', { message: 'hello' }, {
  dryRun: false,
  context: {
    workspaceId: 'ws-123',
    userId: 'user-123',
    requestContext: { source: 'ui' }
  }
})
console.log('Real execution:', realResult)
// status === 'success', outputs.echoed === 'hello'
```
  </verify>
  <done>Tool Executor handles dry-run, permissions, and logging correctly.</done>
</task>

</tasks>

<verification>
1. `import { logger } from '@/lib/audit/logger'` works
2. `import { logToolExecution } from '@/lib/audit/tool-logger'` works
3. `import { toolRegistry } from '@/lib/tools/registry'` works
4. `import { executeTool } from '@/lib/tools/executor'` works
5. Register a tool, execute with dry-run=true, verify status is 'dry_run'
6. Register a tool, execute with dry-run=false, verify execution logged to DB
7. Pass invalid inputs, verify ValidationError thrown with details
</verification>

<success_criteria>
- Pino logger redacts sensitive fields
- Tool Logger persists to tool_executions table
- Registry validates inputs with Ajv
- Registry supports listTools() discovery
- Executor supports dry-run mode
- Executor logs all executions (success, error, dry_run)
- ValidationError and PermissionError are properly thrown
</success_criteria>

<output>
After completion, create `.planning/phases/03-action-dsl-core/03-02-SUMMARY.md`
</output>
